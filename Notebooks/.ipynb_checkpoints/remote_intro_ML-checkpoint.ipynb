{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives \n",
    "\n",
    "By the end of this class, you should be able to...\n",
    "\n",
    "- Recall what we have learned in DS 1.1 as a Data Analyst\n",
    "- Understand what we are going to learn in DS 2.1 which covers:\n",
    "    - Machine Learning Components\n",
    "    - Data Preprocessing in Machine Learning\n",
    "        - Data Scaling (Normalization)\n",
    "        - Convert categorical feature to numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we learned in DS 1.1 as a Data Analyst\n",
    "\n",
    "### Question: What do YOU remember from DS 1.1??\n",
    "\n",
    "Don't look ahead! Share with the class your favorite topic, your most challenging topic, or both!\n",
    "- Working with Time Series analysis\n",
    "\n",
    "### Core Concepts:\n",
    "\n",
    "* The principles of effective storytelling\n",
    "\n",
    "* How to make proposals and decisions based on analysis\n",
    "\n",
    "* Exploratory Data Analysis (EDA), focusing on the basics of statistical inference, hypothesis testing, correlation\n",
    "\n",
    "* Check this out as a good resource for Data Analyst VS. Data Engineer VS. Data Scientist roles:\n",
    "\n",
    "https://www.springboard.com/blog/data-engineer-vs-data-scientist/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we are going to learn in DS 2.1\n",
    "\n",
    "### Question: What is machine learning?\n",
    "\n",
    "Share with the class what you think machine learnning is, and how we could use it!\n",
    "\n",
    "### Our definition:\n",
    "\n",
    "* Using data and algorithms that predict or classify unseen, upcoming data with acceptable accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two major machine learning algorithms:\n",
    "\n",
    "1. Supervised Learning\n",
    "\n",
    "2. Unsupervised Learning\n",
    "\n",
    "**Supervised learning** is used for:\n",
    "\n",
    "1. Regression --> Temperature prediction, stock market prediction, next purchased item prediction\n",
    "\n",
    "2. Classification --> Is an email spam or not-spam? Is the image of a dog or cat? Is a comment about a post positive, negative or neutral?\n",
    "\n",
    "**Unsupervised learning** is used for:\n",
    "\n",
    "1. Clustering data into groups\n",
    "\n",
    "2. Reducing the dimension of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Components:\n",
    "\n",
    "<img src=\"Images/machine_learning.png\" width=\"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Level of Math Do We Need for Machine Learning?\n",
    "\n",
    "DS 2.1 does require some higher-level math concepts. You should spend some time refreshing or learning the following topics:\n",
    "\n",
    "**You can review these concepts in [QL 1.1](https://github.com/Make-School-Courses/QL-1.1-Quantitative-Reasoning)!**\n",
    "\n",
    "1. Calculus - Derivatives, Linear Regression\n",
    "    1. Class 8 and 9 from QL 1.1\n",
    "1. Linear Algebra - Intro to Vectors and Matrix Multiplication\n",
    "    1. Class 11 from QL 1.1\n",
    "1. Probability and statistics - Mean, Median, Mode, Standard deviation, Variance and Percentiles, Correlation and Covariance, PDFs, CDFs\n",
    "    1. Classes 2-7 from QL 1.1\n",
    "\n",
    "<img src=\"Images/intro_2.png\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing for Machine Learning: Data Scaling \n",
    "\n",
    "**Data Scaling or Normalization**: Assume we have a dataset with 2 columns. The values of one column are much larger than the values of the second column. The goal of data scaling is to scale the columns to be in the same range.\n",
    "\n",
    "To help us learn more about preprocessing and scaling, we're going to take some time to research these topics through the following guides, articles, and documentation. We will then come back to apply these learnings through some coding challenges!\n",
    "\n",
    "**Please read the following:**\n",
    "\n",
    "- Preparing Data section: https://www.tutorialspoint.com/machine_learning_with_python/machine_learning_with_python_preparing_data.htm\n",
    "\n",
    "- Section 6.3.1: https://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling\n",
    "\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html\n",
    "\n",
    "- Also, look at the first page here: https://www.analyticsvidhya.com/infographics/Scikit-Learn-Infographic.pdf\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity for Data Scaling: Max_Min Scaler\n",
    "\n",
    "**You will do this activity in groups of 4**\n",
    "\n",
    "A two dimensional array (Matrix) X is given, write a function `max_min_s` that for each column:\n",
    "\n",
    "1. Obtains the minimum value of the column (min)\n",
    "1. Obtains the range of the column (range)\n",
    "1. For each value in the column, calculate the following: (value-min)/range\n",
    "\n",
    "**Remember**: the range is the difference between the maximum element and minimum element of each column\n",
    "    \n",
    "Use this dataset as an example input to your function: `X_train = np.array([[1000.0, 2.0], [1500.0, 3.0]])`\n",
    "\n",
    "We will use breakout rooms in Zoom for group work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1000.    2.]\n",
      " [1500.    3.]]\n",
      "[[0. 0.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def max_min_s(X):\n",
    "    # the two-step process as described above\n",
    "    return (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "\n",
    "X_train = np.array([[1000.0, 2.0], [1500.0, 3.0]])\n",
    "print(X_train)\n",
    "print(max_min_s(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the Sklearn preprocessing package to do the same thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Let's use the Sklearn preprocessing package to do the same thing as our above function:\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install sklearn\n",
    "from sklearn import preprocessing\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_minmax = min_max_scaler.fit_transform(X_train)\n",
    "print(X_minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity for Data Scaling: Standard Scaler\n",
    "\n",
    "**You will do this activity in groups of 4**\n",
    "\n",
    "A two dimensional array (Matrix) X is given, write a function that for each column:\n",
    "\n",
    "1. Obtain the mean for the column (mean)\n",
    "1. Obtain the standard deviation for the column (std)\n",
    "1. For each value in the column, calculate the following: (value - mean)/std\n",
    "\n",
    "We will use breakout rooms in Zoom for group work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1. -1.]\n",
      " [ 1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "def standard_s(X):\n",
    "    return (X - X.mean(axis=0)) /X.std(axis=0) \n",
    "\n",
    "print(standard_s(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets use Sklearn preprecoessing package to do the same thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1. -1.]\n",
      " [ 1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "standard_scaler = preprocessing.StandardScaler()\n",
    "X_ss = standard_scaler.fit_transform(X_train)\n",
    "print(X_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing for Machine Learning: Label Encoding and One-Hot Encoding\n",
    "\n",
    "- **Label Encoding** is when we convert categories to a numerical value. For example, the name of countries (France, Germany, Spain) into numbers (0, 1, 2)\n",
    "\n",
    "- **One-Hot Encoding** converts the output of a label encoder (numbers) to a vector consisting only of 1s and 0s (positive/negative)\n",
    "\n",
    "The below image shows an example of one-hot encoding. Each row in the second table represents the values in the Color table. That's why the Red column has 1s in the first two rows, since the first two rows of the Color table are Red\n",
    "\n",
    "<img src=\"Images/One-Hot-Encoding-Diagram.png\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity for Label-Encoder and One-Hot-Encoder:\n",
    "\n",
    "**You will do this activity in groups of 4**\n",
    "\n",
    "We want to be able to make future predicitions on if a person will exit (churn) based on a variety of features. However, not all of our data is numerical: Geography and Gender are categorical, so we can't make predictions using machine learning until we encode them as numbers.\n",
    "\n",
    "Your goal is to convert the Geography and Gender columns of the [Churn_Modelling](Datasets/Churn_Modelling.csv) dataset to numbers, then one-hot representation.\n",
    "\n",
    "We'll use breakout rooms again for this! Later we'll go over how to do this as a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-6619d791546c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Read in the CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Churn_Modelling.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Read in the CSV file\n",
    "df = pd.read_csv('Churn_Modelling.csv')\n",
    "\n",
    "# Print out the first 5 rows of each column in a readable format\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two columns have categorical values: Geography and Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-84a1987281f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Print the unique values from the Geography column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Geography'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Print the unique values from the Geography column\n",
    "print(df['Geography'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-48cac0c44fcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Print the unique values from the Gender column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Gender'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Print the unique values from the Gender column\n",
    "print(df['Gender'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the feature matrix and target column\n",
    "\n",
    "**Target column:** The column we are trying to predict values for. We will test against the values here to see if our predictions are accurate with the current data. Later, for new customers, we want to be able to predict the possibility that the customer will exit based on the 10 features we are looking at in our matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature matrix\n",
    "# We don't care about first 3 columns (RowNumber, CustomerId, Surname),\n",
    "# as those don't factor in to whether a person churns or not\n",
    "X = df.iloc[:, 3:13].values\n",
    "\n",
    "# Target column\n",
    "# We want to predict the exit value,\n",
    "# which therefore makes it our target column\n",
    "y = df.iloc[:, 13].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print the first 10 rows of the feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[0:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Label Encoder to the second and third columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = label_encoder_X_1.fit_transform(X[:, 1])\n",
    "label_encoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = label_encoder_X_2.fit_transform(X[:, 2])\n",
    "print(X[0:10,:])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LabelEncoder has replaced France with 0, Germany with 1, and Spain with 2.  What else do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(categorical_features=[1, 2])\n",
    "X = one_hot_encoder.fit_transform(X).toarray()\n",
    "print(pd.DataFrame(X[0:10,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can do Label encoding and one-hot encoding at the same time in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X = df.iloc[:, 3:13]\n",
    "y = df.iloc[:, 13]\n",
    "pd.get_dummies(X).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(X).head(10).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- [Full Tutorials Point guide on Machine Learning with Python](https://www.tutorialspoint.com/machine_learning_with_python/machine_learning_with_python_quick_guide.htm)\n",
    "- [Scikit Learn Preprocessing documentation](https://scikit-learn.org/stable/modules/preprocessing.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
