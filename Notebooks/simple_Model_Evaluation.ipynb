{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "- So far, learned about two classifiers:\n",
    "\n",
    "    - SVM\n",
    "    \n",
    "    - Logistic Regression\n",
    "    \n",
    "- How we can evalute which model performs better for our classification task?\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets review the confusion matrix we obtained from logistic regression model for diabetes dataset\n",
    "\n",
    "<img src=\"Images/confusion_matrix.png\" width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Model Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is accuracy, recall, precision, Specificity and F1-score?\n",
    "\n",
    "- Accuracy, recall, precision, Specificity and F1-score are all obtained from Confision Matrix elements known as : TN, FP, FN, TP\n",
    "\n",
    "Accuracy: overall, how often is the classifier correct? -> $accuracy = \\frac {TP + TN}{TP+TN+FP+FN}$\n",
    "\n",
    "Classification error: overall, how often is the classifier incorrect? -> $error = 1- accuracy = \\frac {FP + FN}{TP + TN + FP + FN}$\n",
    "\n",
    "Recall: when the actual value is positive, how often is the prediction correct? -> $recall = \\frac {TP}{TP + FN}$\n",
    "\n",
    "Precision: When a positive value is predicted, how often is the prediction correct? -> $precision = \\frac {TP}{TP + FP}$\n",
    "\n",
    "Specificity: When the actual value is negative, how often is the prediction correct? -> $Specificity = \\frac {TN}{TN + FP}$\n",
    "\n",
    "F1-score = 2 x (Precision x Recall )/(Precision + Recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity:  Write a function that returns Accuray, Precision, Recall, F1-score from Confision Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6927083333333334, 0.5555555555555556, 0.24193548387096775, 0.3370786516853933)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "# confusion = metrics.confusion_matrix(y_test, y_pred)\n",
    "# print(confusion)\n",
    "\n",
    "confusion = np.array([[118., 12.], [ 47., 15.]])\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]\n",
    "TP = confusion[1, 1]\n",
    "\n",
    "Accuray = ((TP + TN) / float(TP + TN + FP + FN))\n",
    "\n",
    "Precision = TP / float(TP + FP)\n",
    "\n",
    "Recall = TP / float(FN + TP)\n",
    "\n",
    "F1_score = 2*Precision*Recall/float(Precision+Recall)\n",
    "\n",
    "print((Accuray, Precision, Recall, F1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity (Reminder): How we can obtain y_pred (whose elements are 0 and 1) from :\n",
    "\n",
    "- `y_pred_prob = logreg.predict_proba(X_test)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity: Change the threshold of Logistic Regression (y_pred_prob) to get new confusion matrix and better model performance\n",
    "\n",
    "- The question now is which threshold is better?\n",
    "\n",
    "- To do this:\n",
    "\n",
    "1- Train `logreg = LogisticRegression()` and get `y_pred_prob = logreg.predict_proba(X_test)`\n",
    "\n",
    "2- The second column of `y_pred_prob` is the probability that a subject be diabetes \n",
    "\n",
    "3- Plot histogram of second column. Hint: `plt.hist(y_pred_prob[:, 1], bins=8) plt.show()`\n",
    "\n",
    "4- Count how many of `y_train` is 0 how many is 1. Define thershold as `threshold = y_train.value_counts()[1] / len(y_train)`\n",
    "\n",
    "5- Write a function that returns 0 if `y_pred_prob[:, 1]` is less than threshold, else returns 1 for all elements in `y_pred_prob`\n",
    "\n",
    "6- Calculate the Confuction Matrix by `confusion = metrics.confusion_matrix(y_test, y_pred)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
      "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
      "      dtype='object')\n",
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pima = pd.read_csv('datasets/diabetes.csv')\n",
    "print(pima.columns)\n",
    "print(pima.head())\n",
    "\n",
    "feature_cols = ['Pregnancies', 'Insulin', 'BMI', 'Age']\n",
    "\n",
    "X = pima[feature_cols]\n",
    "# print(X)\n",
    "# y is a vector, hence we use dot to access 'label'\n",
    "y = pima['Outcome']\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# fit model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_prob = logreg.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.61405867, 0.38594133],\n",
       "       [0.7505398 , 0.2494602 ],\n",
       "       [0.74167648, 0.25832352],\n",
       "       [0.60291327, 0.39708673],\n",
       "       [0.88426611, 0.11573389],\n",
       "       [0.87695895, 0.12304105],\n",
       "       [0.50819992, 0.49180008],\n",
       "       [0.44582289, 0.55417711],\n",
       "       [0.77950769, 0.22049231],\n",
       "       [0.25853303, 0.74146697],\n",
       "       [0.67706284, 0.32293716],\n",
       "       [0.17592894, 0.82407106],\n",
       "       [0.65188551, 0.34811449],\n",
       "       [0.81908609, 0.18091391],\n",
       "       [0.57723535, 0.42276465],\n",
       "       [0.84784349, 0.15215651],\n",
       "       [0.55345312, 0.44654688],\n",
       "       [0.92650973, 0.07349027],\n",
       "       [0.53364769, 0.46635231],\n",
       "       [0.64953808, 0.35046192],\n",
       "       [0.52797559, 0.47202441],\n",
       "       [0.60807542, 0.39192458],\n",
       "       [0.84629224, 0.15370776],\n",
       "       [0.55795178, 0.44204822],\n",
       "       [0.89896018, 0.10103982],\n",
       "       [0.77361357, 0.22638643],\n",
       "       [0.94411931, 0.05588069],\n",
       "       [0.25730962, 0.74269038],\n",
       "       [0.89509503, 0.10490497],\n",
       "       [0.83251508, 0.16748492],\n",
       "       [0.58625055, 0.41374945],\n",
       "       [0.65574922, 0.34425078],\n",
       "       [0.81749824, 0.18250176],\n",
       "       [0.62609985, 0.37390015],\n",
       "       [0.9154389 , 0.0845611 ],\n",
       "       [0.61216407, 0.38783593],\n",
       "       [0.55602604, 0.44397396],\n",
       "       [0.8907511 , 0.1092489 ],\n",
       "       [0.72485084, 0.27514916],\n",
       "       [0.71828222, 0.28171778],\n",
       "       [0.75330756, 0.24669244],\n",
       "       [0.59727892, 0.40272108],\n",
       "       [0.77810133, 0.22189867],\n",
       "       [0.73660529, 0.26339471],\n",
       "       [0.33126055, 0.66873945],\n",
       "       [0.99293474, 0.00706526],\n",
       "       [0.89371627, 0.10628373],\n",
       "       [0.82316229, 0.17683771],\n",
       "       [0.67464197, 0.32535803],\n",
       "       [0.75904607, 0.24095393],\n",
       "       [0.717535  , 0.282465  ],\n",
       "       [0.79085101, 0.20914899],\n",
       "       [0.2065381 , 0.7934619 ],\n",
       "       [0.62195525, 0.37804475],\n",
       "       [0.57032158, 0.42967842],\n",
       "       [0.91056727, 0.08943273],\n",
       "       [0.85371019, 0.14628981],\n",
       "       [0.25744554, 0.74255446],\n",
       "       [0.85648956, 0.14351044],\n",
       "       [0.98069321, 0.01930679],\n",
       "       [0.31541112, 0.68458888],\n",
       "       [0.53965397, 0.46034603],\n",
       "       [0.91881687, 0.08118313],\n",
       "       [0.74688679, 0.25311321],\n",
       "       [0.78849857, 0.21150143],\n",
       "       [0.74163683, 0.25836317],\n",
       "       [0.53169448, 0.46830552],\n",
       "       [0.83717831, 0.16282169],\n",
       "       [0.58116011, 0.41883989],\n",
       "       [0.61016075, 0.38983925],\n",
       "       [0.84201271, 0.15798729],\n",
       "       [0.781084  , 0.218916  ],\n",
       "       [0.75640512, 0.24359488],\n",
       "       [0.35984953, 0.64015047],\n",
       "       [0.50882589, 0.49117411],\n",
       "       [0.75744254, 0.24255746],\n",
       "       [0.38253628, 0.61746372],\n",
       "       [0.60871247, 0.39128753],\n",
       "       [0.76336912, 0.23663088],\n",
       "       [0.65281932, 0.34718068],\n",
       "       [0.40808608, 0.59191392],\n",
       "       [0.62838457, 0.37161543],\n",
       "       [0.73326144, 0.26673856],\n",
       "       [0.94558795, 0.05441205],\n",
       "       [0.68804247, 0.31195753],\n",
       "       [0.51428508, 0.48571492],\n",
       "       [0.89069093, 0.10930907],\n",
       "       [0.45252788, 0.54747212],\n",
       "       [0.31466853, 0.68533147],\n",
       "       [0.56772424, 0.43227576],\n",
       "       [0.84315969, 0.15684031],\n",
       "       [0.84773915, 0.15226085],\n",
       "       [0.80287688, 0.19712312],\n",
       "       [0.9365841 , 0.0634159 ],\n",
       "       [0.5567571 , 0.4432429 ],\n",
       "       [0.8333562 , 0.1666438 ],\n",
       "       [0.42195567, 0.57804433],\n",
       "       [0.47798647, 0.52201353],\n",
       "       [0.28156666, 0.71843334],\n",
       "       [0.67443185, 0.32556815],\n",
       "       [0.40366778, 0.59633222],\n",
       "       [0.8920969 , 0.1079031 ],\n",
       "       [0.61916082, 0.38083918],\n",
       "       [0.93349488, 0.06650512],\n",
       "       [0.64886631, 0.35113369],\n",
       "       [0.69576643, 0.30423357],\n",
       "       [0.87037674, 0.12962326],\n",
       "       [0.82041663, 0.17958337],\n",
       "       [0.90773321, 0.09226679],\n",
       "       [0.83227554, 0.16772446],\n",
       "       [0.86352056, 0.13647944],\n",
       "       [0.47592976, 0.52407024],\n",
       "       [0.51399173, 0.48600827],\n",
       "       [0.73368471, 0.26631529],\n",
       "       [0.523284  , 0.476716  ],\n",
       "       [0.58383702, 0.41616298],\n",
       "       [0.83511709, 0.16488291],\n",
       "       [0.79356945, 0.20643055],\n",
       "       [0.84935308, 0.15064692],\n",
       "       [0.18455801, 0.81544199],\n",
       "       [0.49497994, 0.50502006],\n",
       "       [0.23983627, 0.76016373],\n",
       "       [0.57279533, 0.42720467],\n",
       "       [0.45120363, 0.54879637],\n",
       "       [0.88919016, 0.11080984],\n",
       "       [0.90521361, 0.09478639],\n",
       "       [0.6373993 , 0.3626007 ],\n",
       "       [0.68124056, 0.31875944],\n",
       "       [0.62343431, 0.37656569],\n",
       "       [0.91972909, 0.08027091],\n",
       "       [0.77061675, 0.22938325],\n",
       "       [0.98745901, 0.01254099],\n",
       "       [0.86154678, 0.13845322],\n",
       "       [0.28559258, 0.71440742],\n",
       "       [0.53051843, 0.46948157],\n",
       "       [0.49822827, 0.50177173],\n",
       "       [0.84174184, 0.15825816],\n",
       "       [0.52403993, 0.47596007],\n",
       "       [0.80961576, 0.19038424],\n",
       "       [0.86287336, 0.13712664],\n",
       "       [0.77053719, 0.22946281],\n",
       "       [0.6427399 , 0.3572601 ],\n",
       "       [0.91695589, 0.08304411],\n",
       "       [0.58808154, 0.41191846],\n",
       "       [0.57330082, 0.42669918],\n",
       "       [0.90800378, 0.09199622],\n",
       "       [0.84805805, 0.15194195],\n",
       "       [0.74540401, 0.25459599],\n",
       "       [0.88751563, 0.11248437],\n",
       "       [0.65978388, 0.34021612],\n",
       "       [0.81234904, 0.18765096],\n",
       "       [0.53886087, 0.46113913],\n",
       "       [0.84940284, 0.15059716],\n",
       "       [0.80988179, 0.19011821],\n",
       "       [0.33353713, 0.66646287],\n",
       "       [0.85410452, 0.14589548],\n",
       "       [0.13386878, 0.86613122],\n",
       "       [0.87563377, 0.12436623],\n",
       "       [0.66299179, 0.33700821],\n",
       "       [0.13299261, 0.86700739],\n",
       "       [0.59156358, 0.40843642],\n",
       "       [0.65113013, 0.34886987],\n",
       "       [0.93104625, 0.06895375],\n",
       "       [0.82009953, 0.17990047],\n",
       "       [0.51645791, 0.48354209],\n",
       "       [0.82055911, 0.17944089],\n",
       "       [0.48568406, 0.51431594],\n",
       "       [0.88713464, 0.11286536],\n",
       "       [0.8030187 , 0.1969813 ],\n",
       "       [0.71480885, 0.28519115],\n",
       "       [0.88009508, 0.11990492],\n",
       "       [0.49876643, 0.50123357],\n",
       "       [0.74366719, 0.25633281],\n",
       "       [0.50123396, 0.49876604],\n",
       "       [0.43820152, 0.56179848],\n",
       "       [0.74772139, 0.25227861],\n",
       "       [0.31372169, 0.68627831],\n",
       "       [0.57839064, 0.42160936],\n",
       "       [0.79242576, 0.20757424],\n",
       "       [0.87011182, 0.12988818],\n",
       "       [0.69139772, 0.30860228],\n",
       "       [0.24101981, 0.75898019],\n",
       "       [0.69098429, 0.30901571],\n",
       "       [0.62263485, 0.37736515],\n",
       "       [0.81171615, 0.18828385],\n",
       "       [0.8120945 , 0.1879055 ],\n",
       "       [0.58371685, 0.41628315],\n",
       "       [0.80458515, 0.19541485],\n",
       "       [0.76003771, 0.23996229],\n",
       "       [0.87161463, 0.12838537],\n",
       "       [0.77320321, 0.22679679],\n",
       "       [0.76100516, 0.23899484]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.65625, 0.4791666666666667, 0.7419354838709677, 0.5822784810126582)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "confusion = np.array([[80, 50], [16, 46]])\n",
    "\n",
    "# confusion = np.array([[87, 43], [24, 38]])\n",
    "\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]\n",
    "TP = confusion[1, 1]\n",
    "\n",
    "Accuray = ((TP + TN) / float(TP + TN + FP + FN))\n",
    "\n",
    "Precision = TP / float(TP + FP)\n",
    "\n",
    "Recall = TP / float(FN + TP)\n",
    "\n",
    "F1_score = 2*Precision*Recall/float(Precision+Recall)\n",
    "\n",
    "print((Accuray, Precision, Recall, F1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison\n",
    "\n",
    "- With threshold 0.5 -> `confusion = np.array([[118., 12.], [ 47., 15.]])`\n",
    "\n",
    "- With optimal threshold -> `confusion = np.array([[80, 50], [16, 46]])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.65625, 0.4791666666666667, 0.7419354838709677, 0.5822784810126582)\n",
      "(0.65625, 0.4791666666666667, 0.7419354838709677, 0.5822784810126582)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.65625, 0.4791666666666667, 0.7419354838709677, 0.5822784810126582)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With threshold 0.5\n",
    "print((Accuray, Precision, Recall, F1_score))\n",
    "\n",
    "(0.6927083333333334, 0.5555555555555556, 0.24193548387096775, 0.3370786516853933)\n",
    "\n",
    "# With Optimal Theshold\n",
    "print((Accuray, Precision, Recall, F1_score))\n",
    "\n",
    "(0.65625, 0.4791666666666667, 0.7419354838709677, 0.5822784810126582)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "- Normally in a machine learning process, data is divided into training and test sets; the training set is then used to train the model and the test set is used to evaluate the performance of a model \n",
    "\n",
    "- It is possible that the accuracy obtained on one test is very different to accuracy obtained on another test set using the same algorithm\n",
    "\n",
    "- To see the model performance, we use K-Fold Cross-Validation for performance evaluation where K is any number\n",
    "\n",
    "- Suppose we want to perform 5-fold cross validation\n",
    "\n",
    "\n",
    "<img src=\"Images/cross_validation.png\" width=\"500\" height=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets obtain Accuracy and F1-Score for 5-fold cross validation based on diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "268\n",
      "[0.64935065 0.65584416 0.64935065 0.70588235 0.65359477]\n",
      "0.6628045157456922\n",
      "[0.578125   0.55462185 0.54237288 0.64       0.576     ]\n",
      "0.5782239460190857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pima = pd.read_csv('datasets/diabetes.csv')\n",
    "\n",
    "feature_cols = ['Pregnancies', 'Insulin', 'BMI', 'Age']\n",
    "\n",
    "# X is a matrix,access the features we want in feature_cols\n",
    "X = pima[feature_cols]\n",
    "\n",
    "# y is a vector, hence we use dot to access 'label'\n",
    "y = pima['Outcome']\n",
    "\n",
    "print(y.value_counts()[0])\n",
    "print(y.value_counts()[1])\n",
    "\n",
    "logreg = LogisticRegression(class_weight={1: 500/268})\n",
    "#logreg = LogisticRegression(class_weight={1: y.value_counts()[0]/y.value_counts()[1]})\n",
    "# logreg = LogisticRegression()\n",
    "\n",
    "all_accuracies = cross_val_score(estimator=logreg, X=X, y=y, cv=5, scoring='accuracy')\n",
    "print(all_accuracies)\n",
    "print(all_accuracies.mean())\n",
    "\n",
    "all_f1 = cross_val_score(estimator=logreg, X=X, y=y, cv=5, scoring='f1')\n",
    "print(all_f1)\n",
    "print(all_f1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "plt.hist(y, bins=20)\n",
    "plt.show()\n",
    "\n",
    "y_pd_series = pd.Series(y)\n",
    "y_pd_series.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to choose Models based on Cross-Validation\n",
    "\n",
    "- We want to have low variance result for CV -> pick a model that has lower variance\n",
    "\n",
    "- If two models have low variance result for CV -> pick a model that has higher mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search for Parameter Selection\n",
    "\n",
    "- Machine learning models have hyper-parameters. To know which values of hyper-paramaeters give the best result we need grid search\n",
    "\n",
    "- Question: what does grid search mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'grid_search' from 'sklearn' (/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/sklearn/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-adbe71bd623c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Grid Search for Parameter Selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msvc_param_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'grid_search' from 'sklearn' (/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/sklearn/__init__.py)"
     ]
    }
   ],
   "source": [
    "## Grid Search for Parameter Selection\n",
    "\n",
    "from sklearn import svm, grid_search\n",
    "\n",
    "def svc_param_selection(X, y, nfolds):\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "    grid_search = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=nfolds)\n",
    "    grid_search.fit(X, y)\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
